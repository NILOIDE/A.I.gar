Q-learning:

Default 10x:				414 417 421 | 336 341 345

MAX_TRAINING_STEPS 300k 3x:		423 430 438
=> NEW: 500k TEST: 1M

NUM_ACTIONS 16  5x:			412 417 422 | 316 324 333
Default     25 10x:
NUM_ACTIONS 36  5x:			416 419 423 | 307 326 346

REWARD_SCALE 1 4x:			408 413 418 | 311 332 353
REWARD_SCALE 4 4x:			403 409 415 | 304 324 346

TEST: Higher GRID_SQUARES PER FOV: 13, 15, 17

NUM_NN_BOTS 2 10x:
	Default     0  10x:		220 238 256 | 227 273 320 | 181 195 209
	DEATH_TERM -10  3x:		122 145 167 | 467 525 581 | 138 172 207
	DEATH_TERM -100 3x:		248 281 314 | 590 626 663 | 146 189 231 - not really conv
	DEATH_TERM -500 3x:		269 280 291 | 333 419 505 | 146 175 204 - not really conv
	=> NEW: DEATH_TERM -100 TEST: -50, -150

	Default      1 10x:		220 238 256 | 227 273 320 | 181 195 209
	DEATH_FACTOR 2  3x:		273 299 324 | 237 346 450 | 123 186 250
	DEATH_FACTOR 5  3x:		94  119 144 | 327 391 454 | 134 157 180
	DEATH_FACTOR 10 3x:		188 208 228 | 163 237 310 | 94  162 228
	=> NEW: DEATH_FACTOR 2 TEST: 3,4,5

	FRAME_SKIP_RATE 4   3x:		92  75  108 | 220 280 341 | 77  84  92
	FRAME_SKIP_RATE 6   3x:		155 177 198 | 101 151 202
	FRAME_SKIP_RATE 8   3x:		235 253 270 | 442 495 547 | 127 156 185
	FRAME_SKIP_RATE 10  3x:		162 185 209 | 345 426 527 | 126 153 180
	Default         12 10x:		220 238 256 | 227 273 320 | 181 195 209
	=> NEW: Introduce FSR param for botVsbot. Set it to 8. 
           TEST: FSR=[8(5x), 10] for pellets, FSR=[6,10] for greedy.

	ENABLE_SPLIT 3x:		1349 1405 1461 | 110 170 229
		+MAX_STEPS 300k:	1372 1402 1434 | 144 201 259 - still steadily increases

ACTOR_CRITIC_TYPE "CACLA":
	Default 10x:			335 340 345 | 274 282 289
	
	NUM_NN_BOTS 2 5x:		254 278 302 | 202 243 283 | 177 199 221
		+ENABLE_SPLIT		402 568 735 | 51  65  79  | 341 543 743

	ALPHA   0.0002   5x: 		344 351 358 | 277 291 305
	ALPHA   0.00015  5x:		336 342 348 | 264 282 301
	Default 0.0001  10x:		335 340 345 | 274 282 289
	ALPHA   0.000075 5x:		342 347 351 | 270 285 300
	ALPHA   0.00005  5x:		340 347 353 | 280 289 297
	=> NEW: ALPHA=0.000075 TEST: 0.0001, 0.00005, 0.000025

	MAX_TRAINING_STEPS 50k  3x:	297 308 318
	MAX_TRAINING_STEPS 75k  3x:	316 324 332
	Default	           125k 3x:
	MAX_TRAINING_STEPS 150k 3x:	350 356 361 | 293 296 299

	NOISE_TYPE "Orn-Uhl" 5x:	5.3

	ALPHA_POLICY 0.000025  5x:	327 333 340 | 270 283 397 
	Default      0.00005  10x: 	335 340 345 | 274 282 289
	ALPHA_POLICY 0.0001    5x:	345 350 355 | 289 294 298
	=> NEW: ALPHA_POLICY=0.0001 TEST: 0.000125, 0.00015, 0.000075, 0.00005

	SOFT_TARGET_UPDATES TRUE:
		Default 0.001  5x:	340 346 352 | 279 285 290
		DPG_TAU 0.002  3x:	330 340 349 | 270 283 297
		DPG_TAU 0.01   3x:	342 348 354 | 276 281 286
		DPG_TAU 0.05   3x:	329 336 342 | 242 274 305
		DPG_TAU 0.1    3x:	318 334 350 | 276 296 317
	=> TEST: True with TAU=[0.01, 0.02,0.005]


ACTOR_CRITIC_TYPE "DPG":
	Default 10x:				317 324 330 | 191 210 228
	
	NUM_NN_BOTS 2 5x:			189 211 244 | 80  107 133 | 37 89 142 - not conv
		+ENABLE_SPLIT:			6 - No learning.. check for bugs
		=> TEST: again

	NOISE_TYPE "Orn-Uhl" 5x:		297 307 315 | 91  130 171 - not converged!
	=> TEST: NOISE DECAY = 1, NOISE = 0.15

	Default                  1 10x:		317 324 330 | 191 210 228
	DPG_FEED_ACTION_IN_LAYER 2  5x:		288 303 318 | 184 196 207
	DPG_FEED_ACTION_IN_LAYER 3  5x:		329 337 345 | 181 204 226
	=> TEST: again

	DPG_CRITIC_FUNC "elu"          5x:	322 332 343 | 226 242 258
		+ DPG_ACTOR_FUNC "elu" 5x:	294 312 331 | 212 233 255
	DPG_ACTOR_FUNC "elu"           5x:	323 331 339 | 197 214 230
	TEST: CRITIC="elu"
	
	
	Default			0    10x:	317 324 330 | 191 210 228
	DPG_CRITIC_WEIGHT_DECAY 0.001 5x:	321 328 335 | 199 220 241
	DPG_CRITIC_WEIGHT_DECAY 0.002 5x:	320 328 337 | 207 221 236
	DPG_CRITIC_WEIGHT_DECAY 0.005 5x:	318 327 336 | 208 219 229
	DPG_CRITIC_WEIGHT_DECAY 0.01  5x:	301 316 331 | 184 205 226
	NEW: 0.001 TEST: 0.0015, 0.0005, 0.00075, 0.00125
	


	MAX_TRAINING_STEPS 150k 3x:		283 307 331
	MAX_TRAINING_STEPS 200k 3x:		313 327 341 - took 4:50 hours
	MAX_TRAINING_STEPS 400k 3x:		348 356 364 - took 8:30 hours

	DPG_USE_TARGET_MODELS False 5x:		304 315 327 | 185 206 226

	DPG_USE_CACLA True 5x:			325 331 338 | 219 236 253
	 & DPG_USE_DPG_ACTOR_TRAIN False 5x:	268 276 284 | 215 236 258
	=> TEST: USE_CACLA True

	DPG_Q_VAL_INCREASE 0.75 5x:		285 303 322
	Default		   1   10x:		317 324 330 | 191 210 228
	DPG_Q_VAL_INCREASE 2    5x:		330 337 345 | 172 202 231
	DPG_Q_VAL_INCREASE 3    5x:		303 316 329 | 172 204 236
	DPG_Q_VAL_INCREASE 5    5x:		302 311 320
	=> NEW: DPQ_Q_VAL_INCREASE=2. TEST: 1.5, 2.5

	DPG_ACTOR_ALPHA 0.0000025 5x:		283 293 302 | 138 157 175 - not converged
	DPG_ACTOR_ALPHA 0.000005  5x:		303 316 330 | 178 205 233
	DPG_ACTOR_ALPHA 0.0000075 5x:
	Default         0.00001  10x:
	DPG_ACTOR_ALPHA 0.000025  5x:		307 314 322 | 192 207 222
	DPG_ACTOR_ALPHA 0.000075  5x:		251 262 274
	TEST: 0.000015, 0.00002, 0.0000075, 0.000005

	DPG_CRITIC_ALPHA 0.00005 5x:		240 255 271 - not converged!
	DPG_CRITIC_ALPHA 0.0001  5x:		308 317 326 
	Default          0.0002 10x:		317 324 330 | 191 210 228
	DPG_CRITIC_ALPHA 0.0004  5x:		303 317 331 | 201 222 243
	DPG_CRITIC_ALPHA 0.0008  5x:		317 330 343 | 223 234 245
	DPG_CRITIC_ALPHA 0.001   5x:		339 344 350 | 229 244 259
	=> NEW: 0.0005. TEST: 0.001, 0.00025, 0.00075, 0.0001

	SOFT_TARGET_UPDATES True:
		MAX_TRAINING_STEPS 200k 3x:	333 346 359 | 200 253 307

		Default 0.001  5x:		301 321 332 | 190 215 239
		DPG_TAU 0.002  3x:		291 305 319 
		DPG_TAU 0.005  3x:		298 312 326
		DPG_TAU 0.0075 3x:		307 320 332
		DPG_TAU 0.01   3x:		318 329 341
		DPG_TAU 0.05   3x:		291 314 338
		DPG_TAU 0.1    3x:		269 287 305
	NEW: SOFT_TARGET_UPDATES True TEST: 0.005, 0.0075,0.01, 0.0125, 0.015
					 0.0005, 0.00075 , 0.00125, 0.0015


