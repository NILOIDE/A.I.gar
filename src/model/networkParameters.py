GPUS = 1

# Experience replay:
MEMORY_CAPACITY = 100000
MEMORIES_PER_UPDATE = 40 # Must be divisible by 4 atm due to experience replay

# Q-learning
EXP_REPLAY_ENABLED = True
GRID_VIEW_ENABLED = True
TARGET_NETWORK_STEPS = 1000
TARGET_NETWORK_MAX_STEPS = 2000
DISCOUNT = 0.99
Exploration = True

EPSILON = 0.1 if Exploration else 0 # Exploration rate. 0 == No Exploration
FRAME_SKIP_RATE = 4
GRID_SQUARES_PER_FOV = 6
NUM_OF_GRIDS = 3

#ANN
ALPHA = 0.001 #Learning rate
OPTIMIZER = "Adam"
ACTIVATION_FUNC_HIDDEN = 'sigmoid'
ACTIVATION_FUNC_OUTPUT = 'linear'

#Layer neurons
STATE_REPR_LEN = GRID_SQUARES_PER_FOV * GRID_SQUARES_PER_FOV * NUM_OF_GRIDS
HIDDEN_LAYER_1 = 24
HIDDEN_LAYER_2 = 28
HIDDEN_LAYER_3 = 24
