Q-learning:

Default 10x:
NUM_NN_BOTS 2 6x:

NUM_ACTIONS 16  5x:
Default     25 10x:
NUM_ACTIONS 36  5x:

REWARD_SCALE 1 3x:
REWARD_SCALE 4 3x:

NUM_NN_BOTS 2:
	Default     0   6x:
	DEATH_TERM -10  3x:
	DEATH_TERM -100 3x:
	DEATH_TERM -500 3x:

	Default      1 10x:
	DEATH_FACTOR 2  3x:
	DEATH_FACTOR 5  3x:
	DEATH_FACTOR 10 3x:

	FRAME_SKIP_RATE 4  3x:
	FRAME_SKIP_RATE 6  3x:
	FRAME_SKIP_RATE 8  3x:
	FRAME_SKIP_RATE 10 3x:

ACTOR_CRITIC_TYPE "CACLA":
	Default 10x:
	
	NUM_NN_BOTS 2 5x:

	ALPHA   0.0002   5x:
	ALPHA   0.00015  5x:
	Default 0.0001  10x:
	ALPHA   0.000075 5x:
	ALPHA   0.00005  5x:

	MAX_TRAINING_STEPS 50k  3x:
	MAX_TRAINING_STEPS 75k  3x:
	Default	           125k 3x:
	MAX_TRAINING_STEPS 150k 3x:

	ALPHA_POLICY 0.000025  5x:
	Default      0.00005  10x:
	ALPHA_POLICY 0.0001    5x:

	SOFT_TARGET_UPDATES TRUE:
		Default 0.001  5x:
		DPG_TAU 0.002  3x:
		DPG_TAU 0.01   3x:
		DPG_TAU 0.05   3x:
		DPG_TAU 0.1    3x:


ACTOR_CRITIC_TYPE "DPG":
	Default 10x:
	
	NUM_NN_BOTS 2 5x:

	DPG_USE_TARGET_MODELS False 5x:

	DPG_USE_CACLA True 5x:
		& DPG_USE_DPG_ACTOR_TRAINING False 5x:

	DPG_Q_VAL_INCREASE 0.75 5x:
	Default		   1   10x:
	DPG_Q_VAL_INCREASE 2    5x:
	DPG_Q_VAL_INCREASE 3    5x:
	DPG_Q_VAL_INCREASE 5    5x:


	DPG_ACTOR_ALPHA 0.000025 5x:
	Default         0.00005 10x:
	DPG_ACTOR_ALPHA 0.000075 5x:

	DPG_CRITIC_ALPHA 0.00005 5x:
	DPG_CRITIC_ALPHA 0.0001  5x:
	Default          0.0002 10x:
	DPG_CRITIC_ALPHA 0.0004  5x:
	DPG_CRITIC_ALPHA 0.0008  5x:

	SOFT_TARGET_UPDATES True:
		Default 0.001  5x:
		DPG_TAU 0.002  3x:
		DPG_TAU 0.01   3x:
		DPG_TAU 0.05   3x:
		DPG_TAU 0.1    3x:





















